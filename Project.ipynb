{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.427001Z",
     "start_time": "2025-01-18T12:38:21.422835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from PIL import Image"
   ],
   "id": "2111d6d06c5c3f4c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.446886Z",
     "start_time": "2025-01-18T12:38:21.440883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resize_with_aspect_ratio(image, target_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Resizes an image to fit within a target size while maintaining the aspect ratio.\n",
    "    Adds padding to center the image on a black background.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image to resize.\n",
    "        target_size (tuple): Target dimensions (height, width).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Padded image with the target dimensions.\n",
    "    \"\"\"\n",
    "    # Original and target dimensions\n",
    "    h, w = image.shape[:2]\n",
    "    target_h, target_w = target_size\n",
    "    \n",
    "    # Calculate scale factor and new dimensions\n",
    "    scale = min(target_w / w, target_h / h)\n",
    "    new_dims = (int(w * scale), int(h * scale))\n",
    "    \n",
    "    # Resize image and create padded canvas\n",
    "    resized_image = cv2.resize(image, new_dims, interpolation=cv2.INTER_AREA)\n",
    "    padded_image = np.full((target_h, target_w, 3), 0, dtype=np.uint8)\n",
    "    \n",
    "    # Calculate offsets for centering\n",
    "    y_offset = (target_h - new_dims[1]) // 2\n",
    "    x_offset = (target_w - new_dims[0]) // 2\n",
    "    \n",
    "    # Place resized image on the canvas\n",
    "    padded_image[y_offset:y_offset + new_dims[1], x_offset:x_offset + new_dims[0]] = resized_image\n",
    "    return padded_image"
   ],
   "id": "f31740904e1eb98b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.454038Z",
     "start_time": "2025-01-18T12:38:21.448959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def crop_retina_image(image_bgr, output_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Crops a retina image to the largest contour's bounding rectangle and resizes it.\n",
    "\n",
    "    Parameters:\n",
    "        image_bgr (numpy.ndarray): Input image in BGR format.\n",
    "        output_size (tuple): Target dimensions (height, width).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Cropped and resized image in BGR format.\n",
    "    \"\"\"\n",
    "    # Validate the input image\n",
    "    if image_bgr is None or image_bgr.size == 0:\n",
    "        raise ValueError(\"Invalid or empty input image.\")\n",
    "\n",
    "    # Convert to grayscale and threshold to create a binary mask\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Detect contours and validate their presence\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        raise ValueError(\"No contours found in the input image.\")\n",
    "\n",
    "    # Crop the largest contour's bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "    cropped = image_bgr[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize cropped image and return\n",
    "    return resize_with_aspect_ratio(cropped, target_size=output_size)"
   ],
   "id": "8682fdb8cd1b1ce7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.460462Z",
     "start_time": "2025-01-18T12:38:21.455048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_exposure(image_bgr, over_threshold=200, under_threshold=20, exposure_ratio=0.65):\n",
    "    \"\"\"\n",
    "    Detects whether an image is overexposed or underexposed based on pixel intensity thresholds.\n",
    "\n",
    "    Parameters:\n",
    "        image_bgr (numpy.ndarray): Input image in BGR format.\n",
    "        over_threshold (int): Pixel intensity above this value is considered overexposed (default: 200).\n",
    "        under_threshold (int): Pixel intensity below this value is considered underexposed (default: 20).\n",
    "        exposure_ratio (float): Maximum allowed ratio of over/underexposed pixels (default: 0.7).\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - is_not_overexposed (bool): Whether the image is not overexposed.\n",
    "            - is_not_underexposed (bool): Whether the image is not underexposed.\n",
    "            - over_ratio (float): Ratio of overexposed pixels.\n",
    "            - under_ratio (float): Ratio of underexposed pixels.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate total pixels and counts of overexposed/underexposed pixels\n",
    "    total_pixels = gray.size\n",
    "    overexposed_pixels = np.sum(gray >= over_threshold)\n",
    "    underexposed_pixels = np.sum(gray <= under_threshold)\n",
    "\n",
    "    # Compute the ratios of overexposed and underexposed pixels\n",
    "    over_ratio = overexposed_pixels / total_pixels\n",
    "    under_ratio = underexposed_pixels / total_pixels\n",
    "\n",
    "    # Check if the image is within acceptable exposure limits\n",
    "    is_not_overexposed = over_ratio <= exposure_ratio\n",
    "    is_not_underexposed = under_ratio <= exposure_ratio\n",
    "\n",
    "    # Return the results\n",
    "    return is_not_overexposed, is_not_underexposed, over_ratio, under_ratio"
   ],
   "id": "3de6164a40ca1299",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.490913Z",
     "start_time": "2025-01-18T12:38:21.485468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_output_folders(base_folder):\n",
    "    \"\"\"\n",
    "    Creates necessary output folders for image categorization.\n",
    "\n",
    "    Parameters:\n",
    "        base_folder (str): Path to the base output folder.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys ('Underexposed', 'Overexposed', 'Well-exposed') and paths to the corresponding folders.\n",
    "    \"\"\"\n",
    "    # Ensure the base folder exists\n",
    "    os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "    # Define and create subfolders\n",
    "    folders = {\"Underexposed\": os.path.join(base_folder, \"Underexposed\"),\n",
    "               \"Overexposed\": os.path.join(base_folder, \"Overexposed\"),\n",
    "               \"Well-exposed\": os.path.join(base_folder, \"Well-exposed\")}\n",
    "    for path in folders.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Return the dictionary of folder paths\n",
    "    return folders"
   ],
   "id": "3a672078fc86780",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.497920Z",
     "start_time": "2025-01-18T12:38:21.492919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categorize_and_save_image(image_bgr, image_name, exposure_results, output_folders):\n",
    "    \"\"\"\n",
    "    Categorizes an image based on exposure results and saves it in the appropriate folder.\n",
    "\n",
    "    Parameters:\n",
    "        image_bgr (numpy.ndarray): Image in BGR format to be saved.\n",
    "        image_name (str): Name for the saved image file (without extension).\n",
    "        exposure_results (tuple): Exposure results as (is_not_overexposed, is_not_underexposed, over_ratio, under_ratio).\n",
    "        output_folders (dict): Dictionary of output folder paths with keys ('Underexposed', 'Overexposed', 'Well-exposed').\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - category (str): Exposure category ('Well-exposed', 'Overexposed', 'Underexposed', or 'Error').\n",
    "            - output_path (str or None): Path where the image was saved, or None if an error occurred.\n",
    "            - over_ratio (float): Ratio of overexposed pixels.\n",
    "            - under_ratio (float): Ratio of underexposed pixels.\n",
    "    \"\"\"\n",
    "    # Unpack exposure results\n",
    "    is_not_overexposed, is_not_underexposed, over_ratio, under_ratio = exposure_results\n",
    "\n",
    "    # Determine the category based on exposure results\n",
    "    if is_not_overexposed and is_not_underexposed:\n",
    "        category = \"Well-exposed\"\n",
    "    elif not is_not_overexposed:\n",
    "        category = \"Overexposed\"\n",
    "    elif not is_not_underexposed:\n",
    "        category = \"Underexposed\"\n",
    "    else:\n",
    "        return \"Error\", None, over_ratio, under_ratio\n",
    "\n",
    "    # Construct the output path for the image\n",
    "    output_path = os.path.join(output_folders[category], f\"{image_name}.jpeg\")\n",
    "\n",
    "    # Save the image in BGR format directly\n",
    "    cv2.imwrite(output_path, image_bgr)\n",
    "    \n",
    "    # Return the category, path, and exposure ratios\n",
    "    return category, output_path, over_ratio, under_ratio"
   ],
   "id": "f85ca440bcab7fd1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.515431Z",
     "start_time": "2025-01-18T12:38:21.508438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_images_with_histogram_statistics(image_folder, csv_path, output_folder, output_size=(512, 512), max_workers=8):\n",
    "    \"\"\"\n",
    "    A parallelized pipeline for processing images:\n",
    "    1. Reads a CSV file with image metadata and sets up output folders.\n",
    "    2. Processes images in parallel using a ThreadPoolExecutor.\n",
    "    3. Aggregates histograms and builds a DataFrame with results.\n",
    "\n",
    "    Parameters:\n",
    "        image_folder (str): Path to the folder containing input images.\n",
    "        csv_path (str): Path to the CSV file containing image metadata.\n",
    "        output_folder (str): Path to the folder where categorized images will be saved.\n",
    "        output_size (tuple): Desired output size (width, height) for cropped images. Default is (512, 512).\n",
    "        max_workers (int): Maximum number of worker threads for parallel processing. Default is 8.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - results_df (pd.DataFrame): DataFrame with processing results for all images.\n",
    "            - aggregated_hist (np.ndarray or None): Mean histogram of all processed images (if any).\n",
    "            - std_hist (np.ndarray or None): Standard deviation of histograms across all images (if any).\n",
    "    \"\"\"\n",
    "    # Step 1: Create categorized output folders\n",
    "    output_folders = create_output_folders(output_folder)\n",
    "\n",
    "    # Step 2: Read the CSV file into a DataFrame\n",
    "    labels_df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Initialize containers for results and histograms\n",
    "    all_results = []  # Stores processing results for all images\n",
    "    all_hists = []    # Stores histograms for aggregation\n",
    "\n",
    "    # Step 3: Process images in parallel using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        # Submit a job to the executor for each row in the CSV\n",
    "        for _, row in labels_df.iterrows():\n",
    "            future = executor.submit(process_single_row, row, image_folder, output_folders, output_size)\n",
    "            futures.append(future)\n",
    "\n",
    "        # Process results as futures complete\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=\"Processing in parallel\"):\n",
    "            res = f.result()  # Retrieve the result of the completed task\n",
    "            all_results.append(res)\n",
    "\n",
    "            # If the result contains a valid histogram, store it for aggregation\n",
    "            if \"histogram\" in res and res[\"histogram\"] is not None:\n",
    "                all_hists.append(res[\"histogram\"])\n",
    "\n",
    "    # Step 4: Build a DataFrame from the results\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "\n",
    "    # Step 5: Aggregate histograms across all processed images\n",
    "    if len(all_hists) > 0:\n",
    "        all_hists = np.array(all_hists, dtype=float)  # Convert to a NumPy array for easier computation\n",
    "        aggregated_hist = np.mean(all_hists, axis=0)  # Compute the mean histogram\n",
    "        std_hist = np.std(all_hists, axis=0)          # Compute the standard deviation histogram\n",
    "    else:\n",
    "        aggregated_hist = None  # No histograms to aggregate\n",
    "        std_hist = None         \n",
    "\n",
    "    # Return the final results DataFrame and histogram statistics\n",
    "    return results_df, aggregated_hist, std_hist"
   ],
   "id": "70b5ea5b660df3f2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.529737Z",
     "start_time": "2025-01-18T12:38:21.523743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_single_image(row, results, per_image_histograms, output_size):\n",
    "    \"\"\"\n",
    "    Processes a single image: cropping, resizing, and histogram computation.\n",
    "\n",
    "    Parameters:\n",
    "        row (pd.Series): Row of the DataFrame containing image metadata.\n",
    "        results (list): List to store processing results.\n",
    "        per_image_histograms (list): List to store individual image histograms.\n",
    "        output_size (tuple): Target size for image resizing.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    image_name, label, image_path = row[\"image\"], row[\"level\"], row[\"image_path\"]\n",
    "\n",
    "    if not os.path.isfile(image_path):\n",
    "        results.append({\"image\": image_name, \"label\": label, \"category\": \"File not found\"})\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load and process the image\n",
    "        bgr_image = cv2.imread(image_path)\n",
    "        cropped_bgr = crop_retina_image(bgr_image, output_size)\n",
    "\n",
    "        if cropped_bgr is None or cropped_bgr.size == 0:\n",
    "            raise ValueError(f\"Invalid cropped image for {image_name}\")\n",
    "\n",
    "        # Convert to grayscale and compute histogram\n",
    "        gray_image = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        hist, _ = np.histogram(gray_image.ravel(), bins=256, range=(0, 256), density=False)\n",
    "\n",
    "        per_image_histograms.append(hist)\n",
    "\n",
    "        # Store intermediate results\n",
    "        results.append({\"image\": image_name,\n",
    "                        \"label\": label,\n",
    "                        \"cropped_image\": cropped_bgr,\n",
    "                        \"gray_image\": gray_image})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        results.append({\"image\": image_name, \"label\": label, \"category\": \"Error\"})"
   ],
   "id": "d4fe6d87e9ffcfcf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.536744Z",
     "start_time": "2025-01-18T12:38:21.531746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categorize_images(results, output_folders):\n",
    "    \"\"\"\n",
    "    Categorizes images based on exposure and saves them in respective folders.\n",
    "\n",
    "    Parameters:\n",
    "        results (list): List of results with cropped images.\n",
    "        output_folders (dict): Dictionary of output folder paths.\n",
    "\n",
    "    Returns:\n",
    "        list: Final results with categorization and exposure ratios.\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "\n",
    "    for result in tqdm(results, desc=\"Categorizing Images\"):\n",
    "        if \"cropped_image\" not in result:\n",
    "            final_results.append(result)\n",
    "            continue\n",
    "\n",
    "        cropped_bgr = result.pop(\"cropped_image\")\n",
    "\n",
    "        # Detect exposure and categorize\n",
    "        exposure_results = detect_exposure(cropped_bgr)\n",
    "        category, _, over_ratio, under_ratio = categorize_and_save_image(\n",
    "            cropped_bgr,\n",
    "            result[\"image\"],\n",
    "            exposure_results,\n",
    "            output_folders)\n",
    "\n",
    "        # Update result with categorization details\n",
    "        result.update({\"category\": category,\n",
    "                       \"over_ratio\": over_ratio,\n",
    "                       \"under_ratio\": under_ratio})\n",
    "        final_results.append(result)\n",
    "\n",
    "    return final_results"
   ],
   "id": "7ec923e773a2b755",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.546760Z",
     "start_time": "2025-01-18T12:38:21.542262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_summary_table(results_df):\n",
    "    \"\"\"\n",
    "    Generates a summary table of counts based on category and label.\n",
    "\n",
    "    Parameters:\n",
    "        results_df (pandas.DataFrame): DataFrame containing at least 'category' and 'label' columns.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Summary table with categories as rows, labels as columns, and counts as values.\n",
    "    \"\"\"\n",
    "    # Group by 'category' and 'label', count occurrences, and reshape into a table\n",
    "    return results_df.groupby([\"category\", \"label\"]).size().unstack(fill_value=0)"
   ],
   "id": "811d421802dffdc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.555246Z",
     "start_time": "2025-01-18T12:38:21.548767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_image_exposure_distributions(results_df, threshold=0.65):\n",
    "    \"\"\"\n",
    "    Plots histograms for the distribution of underexposure and overexposure ratios.\n",
    "\n",
    "    Parameters:\n",
    "        results_df (pandas.DataFrame): DataFrame containing 'under_ratio' and 'over_ratio' columns.\n",
    "        threshold (float): Threshold for distinguishing well-exposed images (default: 0.7).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def plot_exposure(ax, data, color, title, label):\n",
    "        \"\"\"\n",
    "        Internal helper to plot a single exposure distribution histogram.\n",
    "\n",
    "        Parameters:\n",
    "            ax (matplotlib.axes.Axes): Axis to plot on.\n",
    "            data (pandas.Series): Exposure ratio data (e.g., 'under_ratio' or 'over_ratio').\n",
    "            color (str): Color for the histogram and regions.\n",
    "            title (str): Title for the subplot.\n",
    "            label (str): Label for the histogram values.\n",
    "        \"\"\"\n",
    "        # Plot histogram\n",
    "        ax.hist(data, bins=128, alpha=0.7, color=color, label=f\"{label} Values\", log=True)\n",
    "        \n",
    "        # Plot threshold line\n",
    "        ax.axvline(x=threshold, color=\"green\", linestyle=\"--\", label=\"Well-Exposed Threshold\")\n",
    "        \n",
    "        # Add shaded regions\n",
    "        ax.fill_betweenx([1, ax.get_ylim()[1]], 0, threshold, color=\"green\", alpha=0.2, label=\"Well-Exposed Region\")\n",
    "        ax.fill_betweenx([1, ax.get_ylim()[1]], threshold, 1, color=color, alpha=0.2, label=f\"{label} Region\")\n",
    "    \n",
    "        # Add titles and labels\n",
    "        ax.set_title(title, fontsize=16)\n",
    "        ax.set_xlabel(f\"{label} Ratio\", fontsize=14)\n",
    "        ax.set_ylabel(\"Number of Images (Log Scale)\", fontsize=14)\n",
    "\n",
    "        # Add grid and set limits\n",
    "        ax.grid(alpha=0.5)\n",
    "        ax.set_xlim(left=0)\n",
    "        # ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f\"{int(y)}\"))\n",
    "        ax.legend(fontsize=12)\n",
    "        \n",
    "\n",
    "    # Create the figure and axes\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    # Plot underexposure and overexposure histograms\n",
    "    plot_exposure(axes[0], results_df[\"under_ratio\"], \"blue\", \"Underexposure Distribution\", \"Underexposure\")\n",
    "    plot_exposure(axes[1], results_df[\"over_ratio\"], \"red\", \"Overexposure Distribution\", \"Overexposure\")\n",
    "\n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "9850d915be065fbe",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.567068Z",
     "start_time": "2025-01-18T12:38:21.560256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_histogram_statistics(aggregated_histogram, std_histogram):\n",
    "    \"\"\"\n",
    "    Plots the aggregated pixel intensity histogram with statistical markers (mean, median, mode)\n",
    "    and the standard deviation range.\n",
    "\n",
    "    Parameters:\n",
    "        aggregated_histogram (np.ndarray): The aggregated histogram of pixel intensities (length 256).\n",
    "        std_histogram (np.ndarray): The standard deviation of the histogram values (length 256).\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define the range of pixel intensities (0 to 255)\n",
    "    intensities = np.arange(256)\n",
    "\n",
    "    # Calculate the mean intensity value\n",
    "    # Mean = Sum(intensity * frequency) / Total frequency\n",
    "    mean_val = np.sum(aggregated_histogram * intensities) / np.sum(aggregated_histogram)\n",
    "\n",
    "    # Calculate the cumulative distribution function (CDF) for the histogram\n",
    "    cdf = np.cumsum(aggregated_histogram) / np.sum(aggregated_histogram)\n",
    "\n",
    "    # Calculate the median intensity value using interpolation\n",
    "    # Median is the intensity at which the CDF reaches 0.5\n",
    "    median_val = np.interp(0.5, cdf, intensities)\n",
    "\n",
    "    # Calculate the mode intensity value\n",
    "    # Mode is the intensity with the maximum frequency\n",
    "    mode_val = intensities[np.argmax(aggregated_histogram)]\n",
    "\n",
    "    # Create a new figure for plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot the aggregated histogram as a bar chart\n",
    "    plt.bar(intensities,aggregated_histogram, color=\"gray\", alpha=0.7, label=\"Mean Histogram\")\n",
    "\n",
    "    # Add the standard deviation range as a shaded area\n",
    "    plt.fill_between(intensities,\n",
    "                     aggregated_histogram - std_histogram,  # Lower bound\n",
    "                     aggregated_histogram + std_histogram,  # Upper bound\n",
    "                     color=\"blue\", alpha=0.3, label=\"Std Dev Range\")\n",
    "\n",
    "    # Add a vertical line for the mean, median and mode values\n",
    "    plt.axvline(mean_val, color=\"red\", linestyle=\"--\", linewidth=1.5,label=f\"Mean: {mean_val:.2f}\")\n",
    "    plt.axvline(median_val, color=\"green\", linestyle=\"--\", linewidth=1.5,label=f\"Median: {median_val:.2f}\")\n",
    "    plt.axvline(mode_val, color=\"orange\", linestyle=\"--\", linewidth=1.5,label=f\"Mode: {mode_val:.0f}\")\n",
    "\n",
    "    plt.title(\"Aggregated Pixel Intensity Histogram with Statistics\", fontsize=16)\n",
    "    plt.xlabel(\"Pixel Intensity\", fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(alpha=0.4)\n",
    "    plt.show()"
   ],
   "id": "6f603a0cff76abcc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.592482Z",
     "start_time": "2025-01-18T12:38:21.585078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def display_exposure_subplots(results_df, output_folder, num_images=5):\n",
    "    \"\"\"\n",
    "    Displays a grid of images categorized by exposure levels (Underexposed, Overexposed, Well-exposed).\n",
    "\n",
    "    Parameters:\n",
    "        results_df (pandas.DataFrame): DataFrame containing image data with a 'category' and 'image' column.\n",
    "        image_folder (str): Path to the folder containing categorized images.\n",
    "        num_images (int): Number of images to display per category (default: 5).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    categories = [\"Underexposed\", \"Overexposed\", \"Well-exposed\"]\n",
    "    fig, axes = plt.subplots(len(categories), num_images, figsize=(15, 9))\n",
    "    fig.suptitle(\"Exposure Categories\", fontsize=16)\n",
    "\n",
    "    for i, category in enumerate(categories):\n",
    "        # Get up to 'num_images' image names for the current category\n",
    "        category_images = results_df[results_df[\"category\"] == category][\"image\"].head(num_images)\n",
    "\n",
    "        for j in range(num_images):\n",
    "            ax = axes[i, j] if len(categories) > 1 else axes[j] \n",
    "            if j >= len(category_images):  # If there are no more images to display\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            image_name = category_images.iloc[j]\n",
    "            image_path = os.path.join(output_folder, category, f\"{image_name}.jpeg\")\n",
    "\n",
    "            if os.path.isfile(image_path):\n",
    "                # Load and display the image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    ax.imshow(image)\n",
    "                    ax.axis(\"off\")\n",
    "                    ax.set_title(image_name, fontsize=10)  # Add image name above the image\n",
    "                else:\n",
    "                    ax.axis(\"off\")\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        # Add row labels using a simple ylabel\n",
    "        axes[i, 0].set_ylabel(category, fontsize=12, fontweight='bold', rotation=0, ha='right', va='center')\n",
    "\n",
    "    # Adjust layout to make room for labels\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.tight_layout(rect=[0.15, 0, 1, 0.95])\n",
    "    plt.show()"
   ],
   "id": "a65503eab2d8b02f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T12:38:21.607910Z",
     "start_time": "2025-01-18T12:38:21.600490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_single_row(row, image_folder, output_folders, output_size):\n",
    "    \"\"\"\n",
    "    Processes a single row of image data:\n",
    "    - Loads an image\n",
    "    - Crops it to the retina area\n",
    "    - Converts it to grayscale\n",
    "    - Computes its histogram\n",
    "    - Detects exposure levels\n",
    "    - Categorizes and saves the image in the appropriate folder\n",
    "    - Returns a dictionary with processing results, including the histogram for aggregation.\n",
    "\n",
    "    Parameters:\n",
    "        row (dict): A dictionary containing metadata about the image (e.g., image name, level).\n",
    "        image_folder (str): Path to the folder containing the input images.\n",
    "        output_folders (dict): Dictionary mapping exposure categories to output folder paths.\n",
    "        output_size (tuple): Desired output size (width, height) for cropped images.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the processed image's details, including:\n",
    "            - image: Image name\n",
    "            - label: Original label from the input data\n",
    "            - category: Exposure category (e.g., underexposed, overexposed)\n",
    "            - over_ratio: Percentage of overexposed pixels\n",
    "            - under_ratio: Percentage of underexposed pixels\n",
    "            - histogram: Grayscale intensity histogram\n",
    "    \"\"\"\n",
    "    # Extract the image name and label from the input row\n",
    "    image_name = row[\"image\"]\n",
    "    label = row[\"level\"]\n",
    "    # Construct the full path to the image file\n",
    "    image_path = os.path.join(image_folder, f\"{image_name}.jpeg\")\n",
    "\n",
    "    # Initialize the result dictionary with default values\n",
    "    result = {\"image\": image_name,\n",
    "              \"label\": label,\n",
    "              \"category\": None,\n",
    "              \"over_ratio\": None,\n",
    "              \"under_ratio\": None}\n",
    "\n",
    "    # Check if the image file exists; if not, categorize as \"File not found\"\n",
    "    if not os.path.isfile(image_path):\n",
    "        result[\"category\"] = \"File not found\"\n",
    "        return result\n",
    "\n",
    "    try:\n",
    "        # Load the image using OpenCV\n",
    "        bgr_image = cv2.imread(image_path)\n",
    "\n",
    "        # Crop the image to focus on the retina area\n",
    "        cropped_bgr = crop_retina_image(bgr_image, output_size)\n",
    "\n",
    "        # Convert the cropped image to grayscale for histogram computation\n",
    "        gray_image = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Compute the grayscale intensity histogram (256 bins, range 0-255)\n",
    "        hist, _ = np.histogram(gray_image.ravel(), bins=256, range=(0, 256), density=False)\n",
    "\n",
    "        # Detect exposure levels (e.g., underexposed, overexposed) in the cropped image\n",
    "        exposure_results = detect_exposure(cropped_bgr)\n",
    "\n",
    "        # Categorize the image based on exposure levels and save it to the appropriate folder\n",
    "        category, _, over_ratio, under_ratio = categorize_and_save_image(\n",
    "            cropped_bgr, image_name, exposure_results, output_folders)\n",
    "\n",
    "        # Update the result dictionary with exposure details and histogram\n",
    "        result[\"category\"] = category\n",
    "        result[\"over_ratio\"] = over_ratio\n",
    "        result[\"under_ratio\"] = under_ratio\n",
    "        result[\"histogram\"] = hist  # Add the histogram for later aggregation\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors during processing\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        result[\"category\"] = \"Error\"\n",
    "\n",
    "    # Return the processed results\n",
    "    return result"
   ],
   "id": "91eb28654b379585",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-18T12:38:21.609918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    # plt.style.use('default')\n",
    "    image_folder = 'Data/train'\n",
    "    output_folder = 'Data/Cropped_W_Exposure'\n",
    "    csv_path = 'Data/trainLabels.csv'\n",
    "\n",
    "    # PARALLEL EXECUTION\n",
    "    results_df, aggregated_histogram, std_histogram = process_images_with_histogram_statistics(image_folder, csv_path, output_folder)\n",
    "\n",
    "    # Save and display results\n",
    "    results_df.to_csv(\"Data/exposure_results_with_labels.csv\", index=False)\n",
    "\n",
    "    summary_table = generate_summary_table(results_df)\n",
    "    print(\"\\nExposure Summary:\")\n",
    "    print(summary_table)\n",
    "    summary_table.to_csv(\"Data/exposure_summary_table.csv\")\n",
    "\n",
    "    # Plot histogram statistics\n",
    "    if aggregated_histogram is not None and std_histogram is not None:\n",
    "        plot_histogram_statistics(aggregated_histogram, std_histogram)\n",
    "\n",
    "    # Display example subplots\n",
    "    display_exposure_subplots(results_df, output_folder)\n",
    "\n",
    "    # Plot distributions\n",
    "    plot_image_exposure_distributions(results_df)"
   ],
   "id": "9d4abf429f43a820",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel:   2%|‚ñè         | 677/35126 [00:17<15:55, 36.04it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# # Load CSV and associate image paths\n",
    "# def load_data(csv_path, image_folder):\n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     df[\"image_path\"] = df[\"image\"].apply(lambda x: os.path.join(image_folder, f\"{x}.jpeg\"))\n",
    "#     return df"
   ],
   "id": "63cf4d8b1c1934bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# # Split data into Train, Validation, and Test sets\n",
    "# def split_data(df, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2, random_state=42):\n",
    "#     assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1.\"\n",
    "#     \n",
    "#     # First split into Train and Temp (Val + Test)\n",
    "#     train_df, temp_df = train_test_split(df, \n",
    "#         test_size=(1 - train_ratio), \n",
    "#         stratify=df[\"level\"], \n",
    "#         random_state=random_state)\n",
    "#     \n",
    "#     # Then split Temp into Validation and Test\n",
    "#     val_df, test_df = train_test_split(temp_df, \n",
    "#         test_size=(test_ratio / (val_ratio + test_ratio)), \n",
    "#         stratify=temp_df[\"level\"], \n",
    "#         random_state=random_state)\n",
    "#     \n",
    "#     return train_df, val_df, test_df"
   ],
   "id": "7f9c36ac059c5041",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# # Load images into memory\n",
    "# def load_images(df):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         image_path = row[\"image_path\"]\n",
    "#         label = row[\"level\"]\n",
    "#         try:\n",
    "#             # Load image and convert to RGB\n",
    "#             image = Image.open(image_path).convert(\"RGB\")\n",
    "#             images.append(image)\n",
    "#             labels.append(label)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading image {image_path}: {e}\")\n",
    "#     return images, labels"
   ],
   "id": "1dc3d8f6d1d5e2ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# # Main script\n",
    "# if __name__ == \"__main__\":\n",
    "#     csv_path = \"trainLabels.csv\"\n",
    "#     image_folder = \"Cropped_W_Exposure\"\n",
    "#     \n",
    "#     # Load dataset\n",
    "#     df = load_data(csv_path, image_folder)\n",
    "#     \n",
    "#     # Split dataset\n",
    "#     train_df, val_df, test_df = split_data(df)\n",
    "#     \n",
    "#     print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n",
    "#     \n",
    "#     # Load images into memory\n",
    "#     train_images, train_labels = load_images(train_df)\n",
    "#     val_images, val_labels = load_images(val_df)\n",
    "#     test_images, test_labels = load_images(test_df)\n",
    "#     \n",
    "#     print(f\"Loaded {len(train_images)} train images, {len(val_images)} validation images, {len(test_images)} test images.\")"
   ],
   "id": "22fd44f662d5f8ce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
